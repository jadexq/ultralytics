diff --git a/ultralytics/cfg/default.yaml b/ultralytics/cfg/default.yaml
index 5babd25..bd10a93 100644
--- a/ultralytics/cfg/default.yaml
+++ b/ultralytics/cfg/default.yaml
@@ -93,17 +93,23 @@ pose: 12.0  # (float) pose loss gain
 kobj: 1.0  # (float) keypoint obj loss gain
 label_smoothing: 0.0  # (float) label smoothing (fraction)
 nbs: 64  # (int) nominal batch size
-hsv_h: 0.015  # (float) image HSV-Hue augmentation (fraction)
-hsv_s: 0.7  # (float) image HSV-Saturation augmentation (fraction)
-hsv_v: 0.4  # (float) image HSV-Value augmentation (fraction)
+# hsv_h: 0.015  # (float) image HSV-Hue augmentation (fraction)
+hsv_h: 0.0  # (float) image HSV-Hue augmentation (fraction)
+# hsv_s: 0.7  # (float) image HSV-Saturation augmentation (fraction)
+hsv_s: 0.0  # (float) image HSV-Saturation augmentation (fraction)
+# hsv_v: 0.4  # (float) image HSV-Value augmentation (fraction)
+hsv_v: 0.0  # (float) image HSV-Value augmentation (fraction)
 degrees: 0.0  # (float) image rotation (+/- deg)
-translate: 0.1  # (float) image translation (+/- fraction)
-scale: 0.5  # (float) image scale (+/- gain)
+# translate: 0.1  # (float) image translation (+/- fraction)
+translate: 0.0  # (float) image translation (+/- fraction)
+# scale: 0.5  # (float) image scale (+/- gain)
+scale: 0.0  # (float) image scale (+/- gain)
 shear: 0.0  # (float) image shear (+/- deg)
 perspective: 0.0  # (float) image perspective (+/- fraction), range 0-0.001
 flipud: 0.0  # (float) image flip up-down (probability)
-fliplr: 0.5  # (float) image flip left-right (probability)
-mosaic: 1.0  # (float) image mosaic (probability)
+fliplr: 0.0  # (float) image flip left-right (probability)
+# mosaic: 1.0  # (float) image mosaic (probability)
+mosaic: 0.0  # (float) image mosaic (probability)
 mixup: 0.0  # (float) image mixup (probability)
 copy_paste: 0.0  # (float) segment copy-paste (probability)
 
diff --git a/ultralytics/cfg/models/v8/yolov8.yaml b/ultralytics/cfg/models/v8/yolov8.yaml
index 2255450..b8837cd 100644
--- a/ultralytics/cfg/models/v8/yolov8.yaml
+++ b/ultralytics/cfg/models/v8/yolov8.yaml
@@ -2,6 +2,7 @@
 # YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect
 
 # Parameters
+ch: 6 # num of input channels #jade
 nc: 80  # number of classes
 scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
   # [depth, width, max_channels]
diff --git a/ultralytics/data/augment.py b/ultralytics/data/augment.py
index 12d09cf..1decc08 100644
--- a/ultralytics/data/augment.py
+++ b/ultralytics/data/augment.py
@@ -487,18 +487,19 @@ class RandomHSV:
     def __call__(self, labels):
         """Applies random horizontal or vertical flip to an image with a given probability."""
         img = labels['img']
-        if self.hgain or self.sgain or self.vgain:
-            r = np.random.uniform(-1, 1, 3) * [self.hgain, self.sgain, self.vgain] + 1  # random gains
-            hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))
-            dtype = img.dtype  # uint8
-
-            x = np.arange(0, 256, dtype=r.dtype)
-            lut_hue = ((x * r[0]) % 180).astype(dtype)
-            lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)
-            lut_val = np.clip(x * r[2], 0, 255).astype(dtype)
-
-            im_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)))
-            cv2.cvtColor(im_hsv, cv2.COLOR_HSV2BGR, dst=img)  # no return needed
+        #jade
+        # if self.hgain or self.sgain or self.vgain: 
+        #     r = np.random.uniform(-1, 1, 3) * [self.hgain, self.sgain, self.vgain] + 1  # random gains
+        #     hue, sat, val = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))
+        #     dtype = img.dtype  # uint8
+
+        #     x = np.arange(0, 256, dtype=r.dtype)
+        #     lut_hue = ((x * r[0]) % 180).astype(dtype)
+        #     lut_sat = np.clip(x * r[1], 0, 255).astype(dtype)
+        #     lut_val = np.clip(x * r[2], 0, 255).astype(dtype)
+
+        #     im_hsv = cv2.merge((cv2.LUT(hue, lut_hue), cv2.LUT(sat, lut_sat), cv2.LUT(val, lut_val)))
+        #     cv2.cvtColor(im_hsv, cv2.COLOR_HSV2BGR, dst=img)  # no return needed
         return labels
 
 
@@ -552,6 +553,7 @@ class LetterBox:
         """Return updated labels and image with added border."""
         if labels is None:
             labels = {}
+        
         img = labels.get('img') if image is None else image
         shape = img.shape[:2]  # current shape [height, width]
         new_shape = labels.pop('rect_shape', self.new_shape)
@@ -584,8 +586,44 @@ class LetterBox:
             img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
         top, bottom = int(round(dh - 0.1)) if self.center else 0, int(round(dh + 0.1))
         left, right = int(round(dw - 0.1)) if self.center else 0, int(round(dw + 0.1))
-        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,
-                                 value=(114, 114, 114))  # add border
+        # print(top, bottom, left, right)
+        #img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,
+        #                         value=(114, 114, 114))  # add border
+        #img = img #jade (aaa...)
+        def copyMakeBorder(image, top, bottom, left, right, border_type, value=None):
+            if len(image.shape) == 2:
+                image = image[:, :, np.newaxis]
+        
+            h, w, c = image.shape
+            new_h = h + top + bottom
+            new_w = w + left + right
+        
+            if value is None:
+                value = [0] * c
+            elif isinstance(value, int):
+                value = [value] * c
+        
+            result = np.zeros((new_h, new_w, c), dtype=image.dtype)
+        
+            if border_type == cv2.BORDER_CONSTANT:
+                for i in range(c):
+                    result[:, :, i] = value[i]
+            elif border_type == cv2.BORDER_REPLICATE:
+                result[top:top + h, left:left + w, :] = image
+                for i in range(top):
+                    result[i, left:left + w, :] = image[0, :, :]
+                for i in range(bottom):
+                    result[i + top + h, left:left + w, :] = image[-1, :, :]
+                for j in range(left):
+                    result[:, j, :] = result[:, left, :]
+                for j in range(right):
+                    result[:, j + left + w, :] = result[:, left + w - 1, :]
+            else:
+                raise ValueError("Unsupported border type")
+        
+            return result
+        img = copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT,
+                                 value=tuple([114]*shape[-1])) # add border
 
         if len(labels):
             labels = self._update_labels(labels, ratio, dw, dh)
@@ -658,12 +696,12 @@ class Albumentations:
             check_version(A.__version__, '1.0.3', hard=True)  # version requirement
 
             T = [
-                A.Blur(p=0.01),
-                A.MedianBlur(p=0.01),
-                A.ToGray(p=0.01),
-                A.CLAHE(p=0.01),
-                A.RandomBrightnessContrast(p=0.0),
-                A.RandomGamma(p=0.0),
+                #A.Blur(p=0.01),
+                #A.MedianBlur(p=0.01),
+                #A.ToGray(p=0.01),
+                #A.CLAHE(p=0.01),
+                #A.RandomBrightnessContrast(p=0.0),
+                #A.RandomGamma(p=0.0),
                 A.ImageCompression(quality_lower=75, p=0.0)]  # transforms
             self.transform = A.Compose(T, bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))
 
diff --git a/ultralytics/data/base.py b/ultralytics/data/base.py
index bfc3cc1..4d4ed84 100644
--- a/ultralytics/data/base.py
+++ b/ultralytics/data/base.py
@@ -52,13 +52,13 @@ class BaseDataset(Dataset):
                  img_path,
                  imgsz=640,
                  cache=False,
-                 augment=True,
+                 augment=False, #jade change defacult to no augmentation
                  hyp=DEFAULT_CFG,
                  prefix='',
                  rect=False,
                  batch_size=16,
                  stride=32,
-                 pad=0.5,
+                 pad=0.5, #jade why not set to 0.0?
                  single_cls=False,
                  classes=None,
                  fraction=1.0):
@@ -69,7 +69,7 @@ class BaseDataset(Dataset):
         self.single_cls = single_cls
         self.prefix = prefix
         self.fraction = fraction
-        self.im_files = self.get_img_files(self.img_path)
+        self.im_files = self.get_img_files(self.img_path) #jade !!!
         self.labels = self.get_labels()
         self.update_labels(include_class=classes)  # single_cls and include_class
         self.ni = len(self.labels)  # number of images
@@ -81,6 +81,8 @@ class BaseDataset(Dataset):
             assert self.batch_size is not None
             self.set_rectangle()
 
+        # print(f'self.augment {self.augment}')
+
         # Buffer thread for mosaic images
         self.buffer = []  # buffer size = batch size
         self.max_buffer_length = min((self.ni, self.batch_size * 8, 1000)) if self.augment else 0
@@ -90,6 +92,7 @@ class BaseDataset(Dataset):
             cache = False
         self.ims, self.im_hw0, self.im_hw = [None] * self.ni, [None] * self.ni, [None] * self.ni
         self.npy_files = [Path(f).with_suffix('.npy') for f in self.im_files]
+        
         if cache:
             self.cache_images(cache)
 
@@ -120,6 +123,7 @@ class BaseDataset(Dataset):
             raise FileNotFoundError(f'{self.prefix}Error loading data from {img_path}\n{HELP_URL}') from e
         if self.fraction < 1:
             im_files = im_files[:round(len(im_files) * self.fraction)]
+        
         return im_files
 
     def update_labels(self, include_class: Optional[list]):
@@ -145,27 +149,36 @@ class BaseDataset(Dataset):
         """Loads 1 image from dataset index 'i', returns (im, resized hw)."""
         im, f, fn = self.ims[i], self.im_files[i], self.npy_files[i]
         if im is None:  # not cached in RAM
-            if fn.exists():  # load npy
-                im = np.load(fn)
+            if fn.exists():  # load npy                
+                im = np.load(fn)            
+                #jade, double the channels
+                #b_,g_,r_ = cv2.split(im)
+                #im = cv2.merge((b_,g_,r_,b_,g_,r_))
             else:  # read image
-                im = cv2.imread(f)  # BGR
+                im = np.load(fn)            
+                #im = cv2.imread(f)  # BGR
+                #jade, double the channels
+                #b_,g_,r_ = cv2.split(im)
+                #im = cv2.merge((b_,g_,r_,b_,g_,r_))
                 if im is None:
                     raise FileNotFoundError(f'Image Not Found {f}')
             h0, w0 = im.shape[:2]  # orig hw
             r = self.imgsz / max(h0, w0)  # ratio
+            # print(f'before {im.shape}') #jade
             if r != 1:  # if sizes are not equal
                 interp = cv2.INTER_LINEAR if (self.augment or r > 1) else cv2.INTER_AREA
                 im = cv2.resize(im, (min(math.ceil(w0 * r), self.imgsz), min(math.ceil(h0 * r), self.imgsz)),
                                 interpolation=interp)
 
             # Add to buffer if training with augmentations
+            # print(f'load_image self.augment: {self.augment}')
             if self.augment:
                 self.ims[i], self.im_hw0[i], self.im_hw[i] = im, (h0, w0), im.shape[:2]  # im, hw_original, hw_resized
                 self.buffer.append(i)
                 if len(self.buffer) >= self.max_buffer_length:
                     j = self.buffer.pop(0)
                     self.ims[j], self.im_hw0[j], self.im_hw[j] = None, None, None
-
+            # print(f'after {im.shape}') #jade
             return im, (h0, w0), im.shape[:2]
 
         return self.ims[i], self.im_hw0[i], self.im_hw[i]
@@ -237,6 +250,8 @@ class BaseDataset(Dataset):
 
     def __getitem__(self, index):
         """Returns transformed label information for given index."""
+        # if not self.augment:
+        # if self.augment:
         return self.transforms(self.get_image_and_label(index))
 
     def get_image_and_label(self, index):
@@ -268,7 +283,8 @@ class BaseDataset(Dataset):
                 # Val transforms
                 return Compose([])
         """
-        raise NotImplementedError
+        return Compose([ToTensor()])
+        #raise NotImplementedError
 
     def get_labels(self):
         """Users can custom their own format here.
diff --git a/ultralytics/data/build.py b/ultralytics/data/build.py
index 8fd8602..5fbf9ef 100644
--- a/ultralytics/data/build.py
+++ b/ultralytics/data/build.py
@@ -75,7 +75,7 @@ def build_yolo_dataset(cfg, img_path, batch, data, mode='train', rect=False, str
         img_path=img_path,
         imgsz=cfg.imgsz,
         batch_size=batch,
-        augment=mode == 'train',  # augmentation
+        augment=False, #jade, orginal: mode == 'train',  # augmentation
         hyp=cfg,  # TODO: probably add a get_hyps_from_cfg function
         rect=cfg.rect or rect,  # rectangular batches
         cache=cfg.cache or None,
diff --git a/ultralytics/data/dataset.py b/ultralytics/data/dataset.py
index 575243f..019aa1f 100644
--- a/ultralytics/data/dataset.py
+++ b/ultralytics/data/dataset.py
@@ -103,6 +103,7 @@ class YOLODataset(BaseDataset):
         """Returns dictionary of labels for YOLO training."""
         self.label_files = img2label_paths(self.im_files)
         cache_path = Path(self.label_files[0]).parent.with_suffix('.cache')
+        
         try:
             import gc
             gc.disable()  # reduce pickle load time https://github.com/ultralytics/ultralytics/pull/1585
@@ -145,12 +146,15 @@ class YOLODataset(BaseDataset):
     # TODO: use hyp config to set all these augmentations
     def build_transforms(self, hyp=None):
         """Builds and appends transforms to the list."""
+        # print(f'dataset build_transforms {self.augment}')
         if self.augment:
             hyp.mosaic = hyp.mosaic if self.augment and not self.rect else 0.0
             hyp.mixup = hyp.mixup if self.augment and not self.rect else 0.0
             transforms = v8_transforms(self, self.imgsz, hyp)
         else:
+            # print(f'---------- do build_transforms ELSE')
             transforms = Compose([LetterBox(new_shape=(self.imgsz, self.imgsz), scaleup=False)])
+            # print(f'---------- transforms {transforms}')
         transforms.append(
             Format(bbox_format='xywh',
                    normalize=True,
@@ -159,6 +163,7 @@ class YOLODataset(BaseDataset):
                    batch_idx=True,
                    mask_ratio=hyp.mask_ratio,
                    mask_overlap=hyp.overlap_mask))
+        # print(f'dataset build_transforms transforms {transforms}')
         return transforms
 
     def close_mosaic(self, hyp):
diff --git a/ultralytics/data/utils.py b/ultralytics/data/utils.py
index 9c036e0..5068e92 100644
--- a/ultralytics/data/utils.py
+++ b/ultralytics/data/utils.py
@@ -25,7 +25,7 @@ from ultralytics.utils.downloads import download, safe_download, unzip_file
 from ultralytics.utils.ops import segments2boxes
 
 HELP_URL = 'See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data'
-IMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'  # image suffixes
+IMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm', 'npy' # image suffixes
 VID_FORMATS = 'asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv', 'webm'  # video suffixes
 PIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders
 IMAGENET_MEAN = 0.485, 0.456, 0.406  # RGB mean
@@ -67,19 +67,24 @@ def verify_image_label(args):
     # Number (missing, found, empty, corrupt), message, segments, keypoints
     nm, nf, ne, nc, msg, segments, keypoints = 0, 0, 0, 0, '', [], None
     try:
+        print('here')
         # Verify images
-        im = Image.open(im_file)
-        im.verify()  # PIL verify
-        shape = exif_size(im)  # image size
-        shape = (shape[1], shape[0])  # hw
-        assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'
-        assert im.format.lower() in IMG_FORMATS, f'invalid image format {im.format}'
-        if im.format.lower() in ('jpg', 'jpeg'):
-            with open(im_file, 'rb') as f:
-                f.seek(-2, 2)
-                if f.read() != b'\xff\xd9':  # corrupt JPEG
-                    ImageOps.exif_transpose(Image.open(im_file)).save(im_file, 'JPEG', subsampling=0, quality=100)
-                    msg = f'{prefix}WARNING ⚠️ {im_file}: corrupt JPEG restored and saved'
+        if os.path.splitext(im_file)[1] == '.npy':
+            im = np.load(im_file)
+            shape = (im.shape[1], im.shape[0])
+        else:
+            im = Image.open(im_file)
+            im.verify()  # PIL verify
+            shape = exif_size(im)  # image size
+            shape = (shape[1], shape[0])  # hw
+            assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'
+            assert im.format.lower() in IMG_FORMATS, f'invalid image format {im.format}'
+            if im.format.lower() in ('jpg', 'jpeg'):
+                with open(im_file, 'rb') as f:
+                    f.seek(-2, 2)
+                    if f.read() != b'\xff\xd9':  # corrupt JPEG
+                        ImageOps.exif_transpose(Image.open(im_file)).save(im_file, 'JPEG', subsampling=0, quality=100)
+                        msg = f'{prefix}WARNING ⚠️ {im_file}: corrupt JPEG restored and saved'
 
         # Verify labels
         if os.path.isfile(lb_file):
diff --git a/ultralytics/engine/trainer.py b/ultralytics/engine/trainer.py
index 5c034cf..3365b7f 100644
--- a/ultralytics/engine/trainer.py
+++ b/ultralytics/engine/trainer.py
@@ -240,6 +240,8 @@ class BaseTrainer:
         self.train_loader = self.get_dataloader(self.trainset, batch_size=batch_size, rank=RANK, mode='train')
         if RANK in (-1, 0):
             self.test_loader = self.get_dataloader(self.testset, batch_size=batch_size * 2, rank=-1, mode='val')
+            #breakpoint()
+            #self.test_loader = self.get_dataloader(self.trainset, batch_size=batch_size, rank=RANK, mode='train')
             self.validator = self.get_validator()
             metric_keys = self.validator.metrics.keys + self.label_loss_items(prefix='val')
             self.metrics = dict(zip(metric_keys, [0] * len(metric_keys)))  # TODO: init metrics for plot_results()?
diff --git a/ultralytics/engine/validator.py b/ultralytics/engine/validator.py
index 4d0f9f5..8ce0727 100644
--- a/ultralytics/engine/validator.py
+++ b/ultralytics/engine/validator.py
@@ -139,7 +139,7 @@ class BaseValidator:
             self.dataloader = self.dataloader or self.get_dataloader(self.data.get(self.args.split), self.args.batch)
 
             model.eval()
-            model.warmup(imgsz=(1 if pt else self.args.batch, 3, imgsz, imgsz))  # warmup
+            model.warmup(imgsz=(1 if pt else self.args.batch, 6, imgsz, imgsz))  # warmup
 
         dt = Profile(), Profile(), Profile(), Profile()
         n_batches = len(self.dataloader)
diff --git a/ultralytics/models/yolo/detect/train.py b/ultralytics/models/yolo/detect/train.py
index e697a05..259dbe2 100644
--- a/ultralytics/models/yolo/detect/train.py
+++ b/ultralytics/models/yolo/detect/train.py
@@ -41,6 +41,7 @@ class DetectionTrainer(BaseTrainer):
 
     def preprocess_batch(self, batch):
         """Preprocesses a batch of images by scaling and converting to float."""
+        #breakpoint()
         batch['img'] = batch['img'].to(self.device, non_blocking=True).float() / 255
         return batch
 
diff --git a/ultralytics/nn/autobackend.py b/ultralytics/nn/autobackend.py
index 6a8e387..717bd8d 100644
--- a/ultralytics/nn/autobackend.py
+++ b/ultralytics/nn/autobackend.py
@@ -443,7 +443,7 @@ class AutoBackend(nn.Module):
          """
         return torch.tensor(x).to(self.device) if isinstance(x, np.ndarray) else x
 
-    def warmup(self, imgsz=(1, 3, 640, 640)):
+    def warmup(self, imgsz=(1, 6, 640, 640)):
         """
         Warm up the model by running one forward pass with a dummy input.
 
diff --git a/ultralytics/utils/plotting.py b/ultralytics/utils/plotting.py
index 9681636..0e73fc3 100644
--- a/ultralytics/utils/plotting.py
+++ b/ultralytics/utils/plotting.py
@@ -347,7 +347,8 @@ def plot_images(images,
         if i == max_subplots:  # if last batch has fewer images than we expect
             break
         x, y = int(w * (i // ns)), int(h * (i % ns))  # block origin
-        im = im.transpose(1, 2, 0)
+        #im = im.transpose(1, 2, 0) #jade
+        im = im[:3,:,:].transpose(1, 2, 0) #jade
         mosaic[y:y + h, x:x + w, :] = im
 
     # Resize (optional)
